From 76e2784341b300e9c8eb14a26a748b18e697c192 Mon Sep 17 00:00:00 2001
From: Donald Sharp <sharpd@nvidia.com>
Date: Mon, 24 Mar 2025 14:11:35 -0400
Subject: [PATCH] zebra: Limit reading packets when MetaQ is full

Currently Zebra is just reading packets off the zapi
wire and stacking them up for processing in zebra
in the future.  When there is significant churn
in the network the size of zebra can grow without
bounds due to the MetaQ sizing constraints.  This
ends up showing by the number of nexthops in the
system.  Reducing the number of packets serviced
to limit the metaQ size to the packets to process
allieviates this problem.

Signed-off-by: Donald Sharp <sharpd@nvidia.com>
---
 zebra/rib.h       |  2 ++
 zebra/zebra_rib.c | 26 +++++++++++++++-----------
 zebra/zserv.c     |  6 ++++++
 3 files changed, 23 insertions(+), 11 deletions(-)

diff --git a/zebra/rib.h b/zebra/rib.h
index 04298eb0f..8dae68811 100644
--- a/zebra/rib.h
+++ b/zebra/rib.h
@@ -468,6 +468,8 @@ extern void meta_queue_free(struct meta_queue *mq, struct zebra_vrf *zvrf);
 extern int zebra_rib_labeled_unicast(struct route_entry *re);
 extern struct route_table *rib_table_ipv6;
 
+extern uint32_t zebra_rib_meta_queue_size(void);
+
 extern void rib_unlink(struct route_node *rn, struct route_entry *re);
 extern int rib_gc_dest(struct route_node *rn);
 extern struct route_table *rib_tables_iter_next(rib_tables_iter_t *iter);
diff --git a/zebra/zebra_rib.c b/zebra/zebra_rib.c
index 439f8919d..188f53109 100644
--- a/zebra/zebra_rib.c
+++ b/zebra/zebra_rib.c
@@ -3318,8 +3318,8 @@ static int rib_meta_queue_add(struct meta_queue *mq, void *data)
 	mq->size++;
 
 	if (IS_ZEBRA_DEBUG_RIB_DETAILED)
-		rnode_debug(rn, re->vrf_id, "queued rn %p into sub-queue %s",
-			    (void *)rn, subqueue2str(qindex));
+		rnode_debug(rn, re->vrf_id, "queued rn %p into sub-queue %s mq size %u", (void *)rn,
+			    subqueue2str(qindex), zrouter.mq->size);
 
 	return 0;
 }
@@ -3351,8 +3351,8 @@ static int rib_meta_queue_nhg_ctx_add(struct meta_queue *mq, void *data)
 	mq->size++;
 
 	if (IS_ZEBRA_DEBUG_RIB_DETAILED)
-		zlog_debug("NHG Context id=%u queued into sub-queue %s",
-			   ctx->id, subqueue2str(qindex));
+		zlog_debug("NHG Context id=%u queued into sub-queue %s mq size %u", ctx->id,
+			   subqueue2str(qindex), zrouter.mq->size);
 
 	return 0;
 }
@@ -3379,8 +3379,8 @@ static int rib_meta_queue_nhg_process(struct meta_queue *mq, void *data,
 	mq->size++;
 
 	if (IS_ZEBRA_DEBUG_RIB_DETAILED)
-		zlog_debug("NHG id=%u queued into sub-queue %s", nhe->id,
-			   subqueue2str(qindex));
+		zlog_debug("NHG id=%u queued into sub-queue %s mq size %u", nhe->id,
+			   subqueue2str(qindex), zrouter.mq->size);
 
 	return 0;
 }
@@ -3426,6 +3426,11 @@ static int mq_add_handler(void *data,
 	return mq_add_func(zrouter.mq, data);
 }
 
+uint32_t zebra_rib_meta_queue_size(void)
+{
+	return zrouter.mq->size;
+}
+
 void mpls_ftn_uninstall(struct zebra_vrf *zvrf, enum lsp_types_t type,
 			struct prefix *prefix, uint8_t route_type,
 			uint8_t route_instance)
@@ -4245,7 +4250,7 @@ static int rib_meta_queue_gr_run_add(struct meta_queue *mq, void *data)
 	mq->size++;
 
 	if (IS_ZEBRA_DEBUG_RIB_DETAILED)
-		zlog_debug("Graceful Run adding");
+		zlog_debug("Graceful Run adding mq size %u", zrouter.mq->size);
 
 	return 0;
 }
@@ -4258,10 +4263,9 @@ static int rib_meta_queue_early_route_add(struct meta_queue *mq, void *data)
 	mq->size++;
 
 	if (IS_ZEBRA_DEBUG_RIB_DETAILED)
-		zlog_debug("Route %pFX(%u) (%s) queued for processing into sub-queue %s",
-			   &ere->p, ere->re->vrf_id,
-			   ere->deletion ? "delete" : "add",
-			   subqueue2str(META_QUEUE_EARLY_ROUTE));
+		zlog_debug("Route %pFX(%u) (%s) queued for processing into sub-queue %s mq size %u",
+			   &ere->p, ere->re->vrf_id, ere->deletion ? "delete" : "add",
+			   subqueue2str(META_QUEUE_EARLY_ROUTE), zrouter.mq->size);
 
 	return 0;
 }
diff --git a/zebra/zserv.c b/zebra/zserv.c
index d85c1ca24..4339e9584 100644
--- a/zebra/zserv.c
+++ b/zebra/zserv.c
@@ -528,6 +528,12 @@ static void zserv_process_messages(struct event *thread)
 	struct stream_fifo *cache = stream_fifo_new();
 	uint32_t p2p = zrouter.packets_to_process;
 	bool need_resched = false;
+	uint32_t meta_queue_size = zebra_rib_meta_queue_size();
+
+	if (meta_queue_size < p2p)
+		p2p = p2p - meta_queue_size;
+	else
+		p2p = 0;
 
 	frr_with_mutex (&client->ibuf_mtx) {
 		uint32_t i;
-- 
2.39.5

